#!/usr/bin/env python3
"""
Prueba r√°pida del A/B Testing en vivo
"""

import sys
sys.path.append('backend')

from mlops.ab_testing import ABTestingSystem
from models.ultimate_hybrid_system import UltimateHybridSystem
from models.final_smart_selector import FinalSmartSelector
import time

def test_ab_live():
    """Probar A/B Testing en vivo"""
    
    print("üß™ PROBANDO A/B TESTING EN VIVO")
    print("=" * 50)
    
    # Inicializar sistemas
    ab_system = ABTestingSystem()
    ultimate_system = UltimateHybridSystem()
    final_system = FinalSmartSelector()
    
    # Iniciar A/B test
    test_id = ab_system.start_ab_test(
        "UltimateHybrid", "FinalSmartSelector",
        ultimate_system, final_system, test_duration_days=1
    )
    
    print(f"‚úÖ Test iniciado: {test_id}")
    
    # Casos de prueba
    test_cases = [
        "fuck you",
        "hello world", 
        "you are stupid",
        "amazing work",
        "hate speech"
    ]
    
    print(f"\nüìä Simulando {len(test_cases)} predicciones...")
    
    for i, text in enumerate(test_cases):
        # Asignar tr√°fico
        variant = ab_system.assign_traffic(test_id, f"user_{i}")
        
        # Obtener modelo
        if variant == 'A':
            model = ultimate_system
            model_name = "UltimateHybrid"
        else:
            model = final_system
            model_name = "FinalSmartSelector"
        
        # Hacer predicci√≥n
        start_time = time.time()
        result = model.predict(text)
        response_time = time.time() - start_time
        
        # Log predicci√≥n
        ab_system.log_prediction(
            test_id, variant, text, 
            result['prediction'], result['confidence'],
            None, response_time
        )
        
        print(f"   {i+1}. '{text}' ‚Üí {result['prediction']} ({variant})")
    
    print("‚úÖ Predicciones registradas")
    
    # Obtener resultados
    print("\nüìà RESULTADOS:")
    print("-" * 30)
    
    results = ab_system.get_test_results(test_id)
    
    if 'error' in results:
        print(f"‚ùå Error: {results['error']}")
    else:
        print(f"Test ID: {results['test_id']}")
        print(f"Total predicciones: {results['total_predictions']}")
        
        model_a = results['model_a']
        model_b = results['model_b']
        
        print(f"\nModelo A: {model_a.get('total_predictions', 0)} predicciones")
        print(f"Modelo B: {model_b.get('total_predictions', 0)} predicciones")
        
        # Verificar archivos
        import os
        log_path = f"backend/mlops/ab_results/{test_id}_logs.jsonl"
        
        if os.path.exists(log_path):
            print(f"‚úÖ Logs guardados en: {log_path}")
            
            # Leer logs
            with open(log_path, 'r') as f:
                logs = [line.strip() for line in f]
            
            print(f"üìÑ L√≠neas en el archivo: {len(logs)}")
            
            # Mostrar primera l√≠nea como ejemplo
            if logs:
                import json
                first_log = json.loads(logs[0])
                print(f"üìù Ejemplo de log: {first_log}")
        else:
            print(f"‚ùå No se encontr√≥ el archivo de logs: {log_path}")
    
    print(f"\nüéØ Test ID para Streamlit: {test_id}")
    print("üì± Ve a http://localhost:8518 ‚Üí A/B Testing ‚Üí Ver Resultados")

if __name__ == "__main__":
    test_ab_live()
